{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import struct as st\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import our data. The data is stored in idx3-ubyte files. Thank you [Siladittya Manna](https://medium.com/@mannasiladittya/converting-mnist-data-in-idx-format-to-python-numpy-array-5cb9126f99f1) for the information on wrangling this data. The format for the image files is shown below.\n",
    "\n",
    "|[offset] | [type] | [value] | [description]|\n",
    "|------|------|------|------|\n",
    "| 0000 | 32 bit integer | 0x00000803(2051)| magic number|\n",
    "| 0004 | 32 bit integer | 60000 | number of images |\n",
    "| 0008 | 32 bit integer | 28 | number of rows|\n",
    "| 0012 | 32 bit integer | 28 | number of columns| \n",
    "| 0016 | unsigned byte  | ?? | pixel |\n",
    "| 0017 | unsigned byte  | ?? | pixel |\n",
    "\n",
    "And the format for the label files is shown below.\n",
    "\n",
    "|[offset] | [type] | [value] | [description]|\n",
    "|------|------|------|------|\n",
    "| 0000 | 32 bit integer | 0x00000803(2051)| magic number|\n",
    "| 0004 | 32 bit integer | 60000 | number of items |\n",
    "| 0016 | unsigned byte  | ?? | pixel |\n",
    "| 0017 | unsigned byte  | ?? | pixel |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = {'images' : 'data/train-images-idx3-ubyte' ,'labels' : 'data/train-labels-idx1-ubyte'}\n",
    "\n",
    "#Open the images IDX file in readable binary mode.\n",
    "with open(filename['images'],'rb') as train_imagesfile:\n",
    "    train_imagesfile.seek(0)\n",
    "    # Read the magic number and the dimensions of the image data-set\n",
    "    magic = st.unpack('>4B',train_imagesfile.read(4))\n",
    "    n_img = st.unpack('>I',train_imagesfile.read(4))[0] #num of images\n",
    "    n_rows = st.unpack('>I',train_imagesfile.read(4))[0] #num of rows\n",
    "    n_col = st.unpack('>I',train_imagesfile.read(4))[0] #num of column\n",
    "    \n",
    "    # read image data into images_array\n",
    "    nBytesTotal = n_img*n_rows*n_col*1 #since each pixel data is 1 byte\n",
    "    train_images = 255 - np.asarray(st.unpack('>'+'B'*nBytesTotal,train_imagesfile.read(nBytesTotal))).reshape((n_img,n_rows,n_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename['labels'],'rb') as train_labels_file:\n",
    "    train_labels_file.seek(0)\n",
    "    # Read the magic number and the dimensions of the image data-set\n",
    "    magic = st.unpack('>4B',train_labels_file.read(4))\n",
    "    n_img = st.unpack('>I',train_labels_file.read(4))[0] #num of images\n",
    "\n",
    "    # read label data into label array\n",
    "    nBytesTotal = n_img*1 #since each label is 1 byte\n",
    "    train_labels = np.asarray(st.unpack('>'+'B'*nBytesTotal,train_labels_file.read(nBytesTotal))).reshape((n_img,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how our numbers look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in train_images:\n",
    "    # Plot\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "    time.sleep(2)\n",
    "    break # I only want to see one for now. comment to loop through entire training set \n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to flatten our data as it is currently stored as $28 \\times 28$ numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy and flatten data\n",
    "train_images_array = train_images.reshape(train_images.shape[0], 28*28).astype(np.float)\n",
    "train_labels_array = train_labels.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the SVM's that will be used to classify the number, we will need to do some preprocessing. SVM's are sensitive to the scaling of the data as it is attempting to maximize the margin of the seperating hyperplane. We will scale our data so that each feature vector in the training data is centered with variance 1. ScitKit learn has a useful standard scaler class that we will utilize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit scaler and scale data\n",
    "scaler = StandardScaler()\n",
    "train_images_array = scaler.fit_transform(train_images_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of multiclass SVM that will be used here is a one versus one strategy for the decision function with a radial basis function kernel. SciKitLearn has implemented a multiclass SVM that can be set to run as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_SVM = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "MNIST_SVM.fit(train_images_array, train_labels_array)\n",
    "\n",
    "# # subset to train faster for testing, first 1000 training examples\n",
    "# MNIST_SVM = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "# MNIST_SVM.fit(train_images_array[:1000], train_labels_array[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model we can now make predictions and measure the resulting test error.\n",
    "First we will load the test data just as we did with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = {'images' : 'data/t10k-images-idx3-ubyte' ,'labels' : 'data/t10k-labels-idx1-ubyte'}\n",
    "\n",
    "#Open the images IDX file in readable binary mode.\n",
    "with open(filename['images'],'rb') as test_imagesfile:\n",
    "    test_imagesfile.seek(0)\n",
    "    # Read the magic number and the dimensions of the image data-set\n",
    "    magic = st.unpack('>4B',test_imagesfile.read(4))\n",
    "    n_img = st.unpack('>I',test_imagesfile.read(4))[0] #num of images\n",
    "    n_rows = st.unpack('>I',test_imagesfile.read(4))[0] #num of rows\n",
    "    n_col = st.unpack('>I',test_imagesfile.read(4))[0] #num of column\n",
    "    \n",
    "    # read image data into images_array\n",
    "    nBytesTotal = n_img*n_rows*n_col*1 #since each pixel data is 1 byte\n",
    "    test_images = 255 - np.asarray(st.unpack('>'+'B'*nBytesTotal,test_imagesfile.read(nBytesTotal))).reshape((n_img,n_rows,n_col))\n",
    "    \n",
    "# make copy and flatten + scale data\n",
    "test_images_array = test_images.reshape(test_images.shape[0], 28*28).astype(np.float)\n",
    "test_images_array = scaler.fit_transform(test_images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename['labels'],'rb') as test_labels_file:\n",
    "    test_labels_file.seek(0)\n",
    "    # Read the magic number and the dimensions of the image data-set\n",
    "    magic = st.unpack('>4B',test_labels_file.read(4))\n",
    "    n_img = st.unpack('>I',test_labels_file.read(4))[0] #num of images\n",
    "\n",
    "    # read label data into label array\n",
    "    nBytesTotal = n_img*1 #since each label is 1 byte\n",
    "    test_labels = np.asarray(st.unpack('>'+'B'*nBytesTotal,test_labels_file.read(nBytesTotal))).reshape((n_img,1))\n",
    "    \n",
    "test_labels_array = test_labels.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us view the first ten test images and their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, image in enumerate(test_images[:10]):\n",
    "    # Plot\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Predicted: {}\".format(MNIST_SVM.predict(test_images_array[index])))\n",
    "    Print(\"Actual: {}\")\n",
    "    time.sleep(2)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the score, which is the mean accuracy of the prediction on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_SVM.score(test_images_array, test_labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
